# Local LLM - tutorial

### Ressources

Twitter : 

[https://twitter.com/GregKamradt](https://twitter.com/GregKamradt)

[https://twitter.com/engineerrprompt](https://twitter.com/engineerrprompt)

[https://x.com/aidfulai?s=21&t=CCpJOf7uAsWtzEff8nKqRA](https://x.com/aidfulai?s=21&t=CCpJOf7uAsWtzEff8nKqRA)

[https://x.com/emollick?s=21&t=CCpJOf7uAsWtzEff8nKqRA](https://x.com/emollick?s=21&t=CCpJOf7uAsWtzEff8nKqRA)

Ismael YouTube playlist : [https://youtube.com/playlist?list=PLIf46k6Q6GjS5qK6O3xSrj9BUL8eYO6HD&si=uoagNRUx_E7FCt9_](https://youtube.com/playlist?list=PLIf46k6Q6GjS5qK6O3xSrj9BUL8eYO6HD&si=uoagNRUx_E7FCt9_)

Assistant prompt : [http://promptperfect.xyz/](http://promptperfect.xyz/)

Hugginface : 

[https://huggingface.co/TheBloke](https://huggingface.co/TheBloke)

[https://huggingface.co/ehartford](https://huggingface.co/ehartford)

### üîó Uncensored models

Uncensored models Guide : [https://erichartford.com/uncensored-models](https://erichartford.com/uncensored-models)

Twitter thread : 

[https://x.com/aidfulai/status/1734132170619551882?s=46&t=CCpJOf7uAsWtzEff8nKqRA](https://x.com/aidfulai/status/1734132170619551882?s=46&t=CCpJOf7uAsWtzEff8nKqRA)

The Bloke : 

[https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML](https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML)

### **What's a model?**

When I talk about a model, I'm talking about a huggingface transformer model, that is instruct trained, so that you can ask it questions and get a response. What we are all accustomed to, using ChatGPT. Not all models are for chatting. But the ones I work with are.

First we have to understand technically why the models are aligned.

Open source AI models are trained from a base model such as LLaMA, GPT-Neo-X, MPT-7b, Pythia. The base model is then finetuned with an instruction dataset, and the purpose of this is to teach it to be helpful, to obey the user, answer questions, and engage in conversation.

The reason is that the instruction dataset is composed of questions and answers, and when the dataset contains answers where the AI is being coy or outright refusing (called Refusals) then the bot learns how to refuse, and under what circumstances to refuse, and how to word the refusals. In other words, it learns alignment.

Enjoy responsibly. You are responsible for whatever you do with the output of these models, just like you are responsible for whatever you do with a knife, a car, or a lighter.

### Fine-tuning services

- Runpod
- 

Roleplay : 

Modele ? 

Dataset fine tuning : peut aussi mettre des exemples

Exemple de quelqu‚Äôun qui a fait fine tuning character 

Invocation / preprompt 

Instruction + exemple 

Sandbox // 

30k/50k/100k 

Thibaud : prompt engineering // 

Preprompt invocation 

Mistral7b 

### Custom GPTs (Open AI)

[https://open.substack.com/pub/oneusefulthing/p/almost-an-agent-what-gpts-can-do?r=mpyl7&utm_medium=ios&utm_campaign=post](https://open.substack.com/pub/oneusefulthing/p/almost-an-agent-what-gpts-can-do?r=mpyl7&utm_medium=ios&utm_campaign=post)

### Tools

- LM studio
- Hugginface
- Mistral 7b
- Yi 200k
- Langchain
- Gpt4all
- Ollama
- Oogabooga webui
- Prompt perfect
- Llama index
- Unsloth (30x speed fine tuning)
- Silly tavern

### Customizing LLM

1. **Bots GPT** : Ce sont des applications ou des services qui utilisent un mod√®le GPT pour interagir avec les utilisateurs, souvent dans un cadre sp√©cifique (comme un assistant client ou un chatbot de divertissement). Ils sont g√©n√©ralement configur√©s pour r√©pondre de mani√®re appropri√©e dans leur domaine d'application.
2. **Custom Instructions dans ChatGPT** : Cela fait r√©f√©rence √† la possibilit√© de donner des directives sp√©cifiques √† ChatGPT pour qu'il r√©ponde d'une certaine mani√®re. Par exemple, vous pouvez demander √† ChatGPT de r√©pondre comme s'il √©tait un personnage de fiction ou de se conformer √† un certain style ou ton.
3. **Prompt Templates** : Ce sont des mod√®les ou des structures de prompts pr√©con√ßus que vous utilisez pour obtenir des r√©ponses coh√©rentes et cibl√©es d'un mod√®le GPT. Ils aident √† formuler des requ√™tes de mani√®re √† guider le mod√®le vers le type de r√©ponse souhait√©.
4. **Fine Tuning** : C'est un processus o√π vous entra√Ænez davantage un mod√®le GPT sur un ensemble de donn√©es sp√©cifique pour qu'il soit plus performant dans un domaine particulier. Par exemple, affiner GPT pour qu'il soit plus comp√©tent en m√©decine ou en droit.
5. **RAGs (Rules as Graphs) dans Langchain** : Les RAGs sont des structures de r√®gles sous forme de graphes qui sont utilis√©es pour contr√¥ler et guider la mani√®re dont un mod√®le de langage g√©n√®re des r√©ponses. C'est une fa√ßon de structurer des r√®gles complexes pour des cas d'utilisation sp√©cifiques.
6. **Langchain** : C'est une biblioth√®que qui permet d'int√©grer des mod√®les de langage dans des applications. Elle offre des outils comme les RAGs pour personnaliser et contr√¥ler le comportement du mod√®le de langage.
7. **Agents** : les agents sont des entit√©s programmables qui utilisent des mod√®les de langage et des structures comme les RAGs pour interagir de mani√®re intelligente et contextuelle. Ils repr√©sentent une couche d‚Äôabstraction au-dessus des mod√®les de langage, fournissant autonomie et sp√©cialisation dans leur comportement.

En r√©sum√© :

- Les bots GPT, les prompt templates et les custom instructions dans ChatGPT sont des m√©thodes pour interagir avec ou guider les mod√®les GPT dans des contextes sp√©cifiques.
- Le fine tuning est une technique d'entra√Ænement pour sp√©cialiser un mod√®le GPT dans un domaine.
- Les RAGs et Langchain fournissent des cadres pour structurer et imposer des r√®gles plus complexes sur les r√©ponses des mod√®les de langage.
- Agents : Des programmes ou modules qui utilisent des mod√®les de langage pour effectuer des t√¢ches sp√©cifiques, souvent guid√©s par des r√®gles ou des logiques complexes comme les RAGs.

Fine tune pour les documents : √©viter la baisse de pertinence dans les requ√™tes d‚Äôinfo du milieu de doc (de it/fin ok) 

Uncensored question 

Sexbot : fine tune to trove censor and fine tune for own data 

[https://www.reddit.com/r/LocalLLaMA/s/tB4DDGXniQ](https://www.reddit.com/r/LocalLLaMA/s/tB4DDGXniQ)

[https://www.reddit.com/r/LocalLLaMA/comments/15b7x1l/what_is_the_best_uncensored_llm_model_for_erp/](https://www.reddit.com/r/LocalLLaMA/comments/15b7x1l/what_is_the_best_uncensored_llm_model_for_erp/)

### Large context

Chat gpt : most important instruction in the end.

![IMG_5441.jpeg](Local%20LLM%20-%20tutorial%20ac430bcb878c4d2ba0fdad574e4b4a2f/IMG_5441.jpeg)

![IMG_5440.jpeg](Local%20LLM%20-%20tutorial%20ac430bcb878c4d2ba0fdad574e4b4a2f/IMG_5440.jpeg)

Fine tuning pourrait √™tre bon pour le bot Joshua. Il faudrait s‚Äôarr√™ter sur une version et refaire plus tard 

### Comme samantha d‚Äô√âric hartford

Samantha est un mod√®le de langage d√©velopp√© par Eric Hartford. Ce mod√®le semble √™tre une version avanc√©e et personnalis√©e d'un mod√®le de langage √† grande √©chelle, similaire aux mod√®les GPT d'OpenAI, avec des am√©liorations sp√©cifiques en termes de quantification et d'utilisation de la m√©moire. Samantha est disponible en plusieurs versions, avec des tailles variables en termes de param√®tres, et semble √™tre optimis√©e pour diff√©rentes utilisations en fonction de ses versions. Les d√©tails techniques incluent des informations sur la quantification des bits et les exigences de m√©moire, ce qui indique une attention particuli√®re √† l'efficacit√© du mod√®le et √† sa capacit√© √† √™tre d√©ploy√© dans diff√©rents environnements informatiques [oai_citation:1,TheBloke/Samantha-1.1-70B-GGML ¬∑ Hugging Face](https://huggingface.co/TheBloke/Samantha-1.1-70B-GGML) [oai_citation:2,TheBloke/Samantha-1.1-70B-GPTQ ¬∑ Hugging Face](https://huggingface.co/TheBloke/Samantha-1.1-70B-GPTQ).

Ces mod√®les sont disponibles sur Hugging Face, une plateforme populaire pour les mod√®les de machine learning, et semblent √™tre con√ßus pour √™tre int√©gr√©s et utilis√©s dans diverses applications de g√©n√©ration de texte, offrant ainsi un degr√© de flexibilit√© et de personnalisation pour des cas d'utilisation sp√©cifiques.

Wizard_vicuna_70k_unfiltered 

‚áí model llama 2 fine tuned avec vicu√±a pour Le uncensored. Mais on fine tune √ßa ou on template prompt ? 

Claude 2 sera toujours au dessus de tout sur l‚Äôanalyse de doc 

Se Focus sur de la mati√®re censur√©e √† analyser ou bien pour role play et ligne de dialogues 

Chatbot + rag

Story idea 

feeding the program a prompt, such as a genre or a character, and then letting it generate a plot or story based on that prompt. 

for¬†[dialogue](https://aicontentfy.com/en/blog/chatgpt-and-future-of-dialogue-generation), character development and scene changes.

editing process by providing alternative lines of dialogue or suggesting ways to improve pacing, ensuring a smooth flow in the script.

### Creative screenwriting assistant

[https://github.com/daveshap/ChatGPT_Custom_Instructions/blob/main/creative_writing_partner.md](https://github.com/daveshap/ChatGPT_Custom_Instructions/blob/main/creative_writing_partner.md)

### Clone writing

0/ Tutoriel

[https://x.com/rowancheung/status/1720797318209831034?s=46&t=CCpJOf7uAsWtzEff8nKqRA](https://x.com/rowancheung/status/1720797318209831034?s=46&t=CCpJOf7uAsWtzEff8nKqRA)

1/ Collect and copy writing sample

2/ prepare : 

You are an expert screenwriter. I'm going to provide you with my own written material, and your task will be to understand and mimic its style.
You'll start this exercise by saying "BEGIN." After, I'll present an example text, to which you'll respond, "CONTINUE". The process will continue similarly with another piece of writing and then with further examples. I'll give you unlimited examples. Your response will only be
"CONTINUE. You're only permitted to change your response when I tell you "FINISHED".
After this, you'll explore and understand the tone, style, and characteristics of my writing based on the samples I've given. Finally, I'll prompt you to craft a new piece of writing on a specified topic, emulating my distinctive writing style.

3/ the more you provide, the better it is

4/ BEGIN, FINISHED // 4 pieces Min.

5/ name the style : Joshua‚Äôs style

6/ 80% style precision with gtp3.5 // but gpt4 any%?

7/ needs big context window (gpt4 128k, Claude 2 200k, llama 100k?)

8/ split files into chunks 

### Chat with document

Framework (langchainetc.) + pypdf2 

‚áí allows the model to interact with API

1 click Packages (gpt4all)

- Read pdf
- Derermine chunk_size
- Determine chunk_overlap
- Embeddings = (OpenAIEmbeddings)
- Query?

Tools 

Super dupera DB

Oogabooga local GPT

Chat with PDF files ‚áí extract data/context ‚áí split in chunks (1,2,3,4) ‚áí embedding (1,2,3,4) ‚áí semantic index 

![IMG_5427.png](Local%20LLM%20-%20tutorial%20ac430bcb878c4d2ba0fdad574e4b4a2f/IMG_5427.png)